{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e3e04-a15a-4a97-bc1b-3437a892ed88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import shutil\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "print(\"\")\n",
    "print(\"+\"*shutil.get_terminal_size().columns)\n",
    "print(\"Hierarchical Bayesian Analysis of Kepler Eccentricities\")\n",
    "print(\"Initialized {0}\".format(datetime.now().strftime(\"%d-%b-%Y at %H:%M:%S\")))\n",
    "print(\"+\"*shutil.get_terminal_size().columns)\n",
    "print(\"\")\n",
    "\n",
    "# track date\n",
    "YYYYMMDD = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# start program timer\n",
    "global_start_time = timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e5116-85a2-416d-bdad-d4fd50a1ab40",
   "metadata": {},
   "source": [
    "## Parse arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643291b5-6dd0-4abb-87ad-63fb54ac64c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import string\n",
    "\n",
    "try:\n",
    "    # read the arguments\n",
    "    parser = argparse.ArgumentParser(description=\"Inputs for Kepler hierarchical eccentricities analysis\")\n",
    "    parser.add_argument(\"--project_dir\", default='/data/user/gjgilbert/projects/kepler-ecc-rp/', type=str, required=False, \\\n",
    "                        help=\"project directory for storing inputs and outputs\")\n",
    "    parser.add_argument(\"--data_dir\", default='/data/user/gjgilbert/data/DR25_chains/', type=str, required=False, \\\n",
    "                        help=\"data directory for accessing DR25 posterior chains\")\n",
    "    parser.add_argument(\"--run_id\", default=None, type=str, required=True, \\\n",
    "                        help=\"unique run identifier\")\n",
    "    parser.add_argument(\"--distribution\", default='empirical', type=str, required=False, \\\n",
    "                        help=\"probability density function to use; can be 'histogram', 'empirical', 'beta', 'halfnormal', 'expon', 'rayleigh', 'invpareto'\")\n",
    "    parser.add_argument(\"--nsamp\", default=1000, type=int, required=False, \\\n",
    "                        help=\"number of (re)samples to feed into hbayes model\")\n",
    "    parser.add_argument(\"--nbin\", default=100, type=int, required=False, \\\n",
    "                        help=\"number of bins for probability density function'\")\n",
    "\n",
    "    parser.add_argument(\"--multiplicity\", default=(1,99), nargs=2, type=int, required=False, \\\n",
    "                        help=\"(lower,upper) limits on multiplicity\")\n",
    "    parser.add_argument(\"--per_lim\", default=(1,300), nargs=2, type=float, required=False, \\\n",
    "                        help=\"(lower,upper) limits on period\")\n",
    "    parser.add_argument(\"--rad_type\", default=None, type=str, required=True, \\\n",
    "                        help=\"radius type to use' can by 'rp', 'rp10', or 'rpadj'\")\n",
    "    parser.add_argument(\"--rad_lim\", default=None, nargs=2, type=float, required=True, \\\n",
    "                        help=\"(lower,upper) limits on radius; set lower=upper to use Gaussian binning\")\n",
    "    parser.add_argument(\"--rad_fwhm\", default=None, type=float, required=False, \\\n",
    "                        help=\"fractional FWHM on radius bins if using Gaussian binning'\")\n",
    "\n",
    "    parser.add_argument(\"--mstar_lim\", default=(0.,10.), nargs=2, type=float, required=False, \\\n",
    "                        help=\"(lower,upper) limits on stellar mass\")\n",
    "    parser.add_argument(\"--rstar_lim\", default=(0.7,1.4), nargs=2, type=float, required=False, \\\n",
    "                        help=\"(lower,upper) limits on stellar radius\")\n",
    "    parser.add_argument(\"--feh_lim\", default=(-0.6,0.6), nargs=2, type=float, required=False, \\\n",
    "                        help=\"(lower,upper) limits on stellar metallicity\")\n",
    "    parser.add_argument(\"--teff_lim\", default=(4700,6500), nargs=2, type=float, required=False, \\\n",
    "                        help=\"(lower,upper) limits on stellar effective temperature\")\n",
    "    parser.add_argument(\"--age_lim\", default=(0,14), nargs=2, type=float, required=False, \\\n",
    "                        help=\"(lower,upper) limits on stellar age\")\n",
    "\n",
    "    parser.add_argument(\"--e_detprior\", default=1, type=int, required=False, \\\n",
    "                        help=\"flag to use geometric eccentricity detection prior (1) or not (0)\")\n",
    "    parser.add_argument(\"--b_detprior\", default=0, type=int, required=False, \\\n",
    "                        help=\"flag to use impact parameter detection prior (1) or not (0)\")\n",
    "\n",
    "    # parse the arguments\n",
    "    args = parser.parse_args()\n",
    "    PROJECT_DIR  = args.project_dir\n",
    "    DATA_DIR     = args.data_dir\n",
    "    RUN_ID       = args.run_id\n",
    "    DISTRIBUTION = args.distribution\n",
    "    NSAMP        = args.nsamp\n",
    "    NBIN         = args.nbin\n",
    "    MULTIPLICITY = args.multiplicity\n",
    "    PER_LIM      = args.per_lim\n",
    "    RAD_TYPE     = args.rad_type\n",
    "    RAD_LIM      = args.rad_lim\n",
    "    RAD_FWHM     = args.rad_fwhm\n",
    "    MSTAR_LIM    = args.mstar_lim\n",
    "    RSTAR_LIM    = args.rstar_lim\n",
    "    FEH_LIM      = args.feh_lim\n",
    "    TEFF_LIM     = args.teff_lim\n",
    "    AGE_LIM      = args.age_lim\n",
    "    E_DETPRIOR   = bool(args.e_detprior)\n",
    "    B_DETPRIOR   = bool(args.b_detprior)\n",
    "\n",
    "\n",
    "except:\n",
    "    PROJECT_DIR  = '/Users/research/projects/kepler-ecc-rp/'\n",
    "    DATA_DIR     = '/Users/research/data/DR25_chains/'\n",
    "    RUN_ID        = 'development_'\n",
    "    DISTRIBUTION = 'empirical'\n",
    "    NSAMP        = 1000\n",
    "    NBIN         = 100\n",
    "    MULTIPLICITY = (1,1)\n",
    "    PER_LIM      = (1,300)\n",
    "    RAD_TYPE     = 'rp10'\n",
    "    #RAD_LIM      = (0.5,16)\n",
    "    #RAD_LIM      = (1.36, 1.50)\n",
    "    #RAD_LIM      = (1.50, 1.67)  # -10% super-Earths\n",
    "    RAD_LIM      = (1.67, 2.02)  # +/- 10% fractional width centered on nominal radius valley\n",
    "    #RAD_LIM      = (2.02, 2.23)  # +10% sub-Neptunes\n",
    "    #RAD_LIM      = (2.23, 2.45)\n",
    "    RAD_FWHM     = None          # fractional full width half max of Gaussian bins (if appliable)\n",
    "    MSTAR_LIM    = (0.,10.)\n",
    "    RSTAR_LIM    = (0.7,1.4)\n",
    "    FEH_LIM      = (-0.6,0.6)\n",
    "    TEFF_LIM     = (4700,6500)\n",
    "    AGE_LIM      = (0,14)\n",
    "    E_DETPRIOR   = True\n",
    "    B_DETPRIOR   = False\n",
    "\n",
    "    # auto-generate random run_id\n",
    "    ascii = string.ascii_letters + string.digits\n",
    "    for i in range(8):\n",
    "        RUN_ID += random.choice(ascii)\n",
    "    \n",
    "    \n",
    "RESULTS_DIR = os.path.join(PROJECT_DIR, 'Results', YYYYMMDD)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "print(\" Distribution: {0}\".format(DISTRIBUTION))\n",
    "print(\"\")\n",
    "print(\"   npl = {0}-{1}\".format(MULTIPLICITY[0], MULTIPLICITY[1]))\n",
    "print(\"   P   = {0}-{1}\".format(PER_LIM[0], PER_LIM[1]))\n",
    "print(\"   {0} = {1}-{2}\".format(RAD_TYPE, RAD_LIM[0], RAD_LIM[1]))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f98707-cb03-452a-99ac-0356b9fa2e2b",
   "metadata": {},
   "source": [
    "## Import packages and define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3142e684-6b19-4d99-b712-9f96b981f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.constants as apc\n",
    "from   copy import deepcopy\n",
    "import diptest\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmap\n",
    "from   matplotlib.colors import LinearSegmentedColormap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from   scipy.interpolate import interp1d, UnivariateSpline, CubicSpline\n",
    "from   scipy import stats\n",
    "from   scipy.special import erf, erfinv\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "import aesara_theano_fallback.tensor as T\n",
    "from   aesara_theano_fallback import aesara as theano\n",
    "from   celerite2.theano import GaussianProcess\n",
    "from   celerite2.theano import terms as GPterms\n",
    "import pymc3 as pm\n",
    "import pymc3_ext as pmx\n",
    "\n",
    "sys.path.append(PROJECT_DIR)\n",
    "from utils.astro import calc_T14_circ, calc_sma, calc_aRs, jacobian, detection_prior, duration_ratio\n",
    "from utils.distributions import BetaDistLogPDF, NormDistLogPDF, ExponDistLogPDF, RayleighDistLogPDF, InvParetoDistLogPDF\n",
    "from utils.eccsamp import imp_sample_rhostar\n",
    "from utils.io import load_dr25_data_from_hdf5\n",
    "from utils.models import build_simple_model, build_multilevel_model\n",
    "from utils.stats import weighted_percentile, draw_random_samples\n",
    "\n",
    "pi = np.pi\n",
    "\n",
    "RSAU = (apc.R_sun/apc.au).value                                 # solar radius [AU]\n",
    "RSRE = (apc.R_sun/apc.R_earth).value                            # R_sun/R_earth\n",
    "RHOSUN_GCM3 = (3*apc.M_sun/(4*pi*apc.R_sun**3)).value/1000      # solar density [g/cm^3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61af8c1e-0e90-40d4-910c-8740bddb8128",
   "metadata": {},
   "source": [
    "## Load DR25 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d168011-3a48-4675-ab26-2587de5c5c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading data...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b93e4ee-5bcb-4fad-90c0-9b2726f8fcc5",
   "metadata": {},
   "source": [
    "#### Load catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce1af56-2e9a-4e84-be89-afc11d205c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "DR25_CATALOG = os.path.join(PROJECT_DIR, 'Catalogs/kepler_dr25_gaia_dr2_crossmatch.csv')\n",
    "catalog = pd.read_csv(DR25_CATALOG, index_col=0)\n",
    "\n",
    "# hard-code period and radius limits\n",
    "use  = (catalog.period > 1) * (catalog.period < 300)\n",
    "use *= (catalog.rp > 0) * (catalog.rp < 16)\n",
    "\n",
    "# remove likely false positives\n",
    "use *= catalog.fpp < 0.1\n",
    "\n",
    "# require better than 20% precision on radius\n",
    "use *= catalog.rp_err/catalog.rp < 0.2\n",
    "\n",
    "# clean up stellar sample\n",
    "use *= catalog.logg > 4.0                                 # surface gravity as proxy for main sequence\n",
    "use *= (catalog.rcf - 1 < 0.05) + np.isnan(catalog.rcf)   # radius correction factor (Furlan+ 2017)\n",
    "use *= catalog.ruwe < 1.4                                 # Gaia RUWE\n",
    "\n",
    "# slice subpopulation\n",
    "use *= ((catalog.npl >= MULTIPLICITY[0]) &\n",
    "        (catalog.npl <= MULTIPLICITY[1]) &\n",
    "        (catalog.period >= PER_LIM[0]) &\n",
    "        (catalog.period <= PER_LIM[1]) &\n",
    "        (catalog.mstar >= MSTAR_LIM[0]) &\n",
    "        (catalog.mstar <= MSTAR_LIM[1]) &\n",
    "        (catalog.rstar >= RSTAR_LIM[0]) &\n",
    "        (catalog.rstar <= RSTAR_LIM[1]) &\n",
    "        (catalog.feh >= FEH_LIM[0]) &\n",
    "        (catalog.feh <= FEH_LIM[1]) &\n",
    "        (catalog.teff >= TEFF_LIM[0]) &\n",
    "        (catalog.teff <= TEFF_LIM[1]) &\n",
    "        (catalog.age >= AGE_LIM[0]) &\n",
    "        (catalog.age <= AGE_LIM[1])\n",
    "       )\n",
    "\n",
    "# update catalog\n",
    "catalog = catalog.loc[use].reset_index(drop=True)\n",
    "targets = np.array(catalog.planet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f2d3c-707c-4da8-99b0-f8e01dd2444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tophat binning\n",
    "if RAD_LIM[0] != RAD_LIM[1]:\n",
    "    use = (catalog[RAD_TYPE] >= RAD_LIM[0]) & (catalog[RAD_TYPE] <= RAD_LIM[1])\n",
    "    \n",
    "    catalog = catalog.loc[use].reset_index(drop=True)\n",
    "    targets = np.array(catalog.planet_name)\n",
    "\n",
    "    catalog['ln_binweight'] = np.zeros(len(targets))\n",
    "\n",
    "\n",
    "# Gaussian binning\n",
    "else:\n",
    "    # grab objects within 3-sigma of bin center\n",
    "    rad_center = RAD_LIM[0]\n",
    "    rad_sigma  = np.sqrt(catalog[RAD_TYPE+'_err']**2 + (RAD_FWHM/2.355*rad_center)**2)\n",
    "    rad_low    = np.max([0.1, np.min(rad_center-3*rad_sigma)])\n",
    "    rad_high   = np.min([20., np.max(rad_center+3*rad_sigma)])\n",
    "\n",
    "    use = np.abs(catalog[RAD_TYPE] - rad_center)/rad_sigma < 3.0\n",
    "    \n",
    "    catalog = catalog.loc[use].reset_index(drop=True)\n",
    "    targets = np.array(catalog.planet_name)\n",
    "\n",
    "    # numerically integrate probabilities for bins, accounting for measurement uncertainty\n",
    "    Ngrid = 1000\n",
    "    grid_over_range = np.linspace(np.log10(rad_low), np.log10(rad_high), Ngrid)\n",
    "    weight_from_bin = stats.norm(np.log10(rad_center), RAD_FWHM/2.355*rad_center).pdf(grid_over_range)\n",
    "    weight_from_obj = np.zeros((len(targets),Ngrid))\n",
    "\n",
    "    for i, t in enumerate(targets):\n",
    "        rad = catalog.loc[catalog.planet_name==t, RAD_TYPE]\n",
    "        rad_err = catalog.loc[catalog.planet_name==t, RAD_TYPE+'_err']\n",
    "        weight_from_obj[i] = stats.norm(np.log10(rad), rad_err/rad/np.log(10)).pdf(grid_over_range)\n",
    "\n",
    "        do_plot=False\n",
    "        if do_plot:\n",
    "            plt.figure(figsize=(4,3))\n",
    "            plt.plot(10**grid_over_range, weight_from_bin)\n",
    "            plt.plot(10**grid_over_range, weight_from_obj[i])\n",
    "            plt.show()\n",
    "\n",
    "    catalog['ln_binweight'] = np.log(np.inner(weight_from_bin, weight_from_obj)) - 2*np.log(Ngrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c97aa3d-5e09-4dee-82eb-e03e206eab66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e710c4c1-d57a-4181-99c1-67e55ad9f70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b23e77-0b4e-4a42-8a2a-456f6079fd86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb7d8bd-89f5-45e7-8fcf-50935f09f391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b46a330-0457-4153-8c27-c44b48953dd7",
   "metadata": {},
   "source": [
    "#### Load posterior chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8643e265-acf2-491c-b89a-aab0d6c1adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "DR25_CHAINS = os.path.join(DATA_DIR, 'dr25-chains_trimmed-thinned.hdf')\n",
    "chains  = {}\n",
    "failure = []\n",
    "\n",
    "# read in the data\n",
    "for i, t in enumerate(targets):\n",
    "    try:\n",
    "        chains[t] = pd.DataFrame(load_dr25_data_from_hdf5(DR25_CHAINS, t))\n",
    "        chains[t]['DUR14'] = calc_T14_circ(chains[t].PERIOD, chains[t].ROR, chains[t].IMPACT, chains[t].RHOTILDE)\n",
    "\n",
    "        if np.any(chains[t].values < 0):\n",
    "            raise ValueError(\"Negative values in posterior chain\")\n",
    "        if np.sum(np.isnan(chains[t].values)) > 0:\n",
    "            raise ValueError(\"NaN values in posterior chain\")\n",
    "            \n",
    "    except:\n",
    "        warnings.warn(\"{0} failed to load\".format(t))\n",
    "        failure.append(t)\n",
    "\n",
    "targets = list(np.array(targets)[~np.isin(targets,failure)])\n",
    "\n",
    "print(\"{0} targets loaded\".format(len(targets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0a44cb-861c-4c24-808b-1ccc1a1a4d91",
   "metadata": {},
   "source": [
    "#### Sanitize chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93111e90-69c5-406f-8ae2-3ad82f5b593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelman_rubin(c):\n",
    "    J, L = c.shape\n",
    "    \n",
    "    mean_of_chain = np.mean(c, axis=1)\n",
    "    mean_of_means = np.mean(mean_of_chain)\n",
    "\n",
    "    B = L/(J-1) * np.sum((mean_of_chain - mean_of_means)**2)\n",
    "    W = (1/J) * np.sum(1/(L-1) * np.sum((c.T - mean_of_chain)**2))\n",
    "\n",
    "    Rhat = ((L-1)/L * W + B/L) / W\n",
    "\n",
    "    return Rhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bcd82b-e0f5-41fa-99b2-9a282e3bd709",
   "metadata": {},
   "outputs": [],
   "source": [
    "density = {}\n",
    "failure = []\n",
    "\n",
    "for i, t in enumerate(targets):\n",
    "    # remove grazing transits\n",
    "    if np.any(chains[t].IMPACT.values  > 1 - chains[t].ROR.values):\n",
    "        failure.append(t)\n",
    "    \n",
    "    # eliminate NaN and zero-valued chains\n",
    "    if np.any(chains[t].values < 0):\n",
    "        failure.append(t)\n",
    "    if np.sum(np.isnan(chains[t].values)) > 0:\n",
    "        failure.append(t)\n",
    "\n",
    "    # check Gelman-Rubin convergence statistic\n",
    "    for k in chains[t].keys():\n",
    "        Rhat = gelman_rubin(chains[t][k].values.reshape(4,-1))\n",
    "        if Rhat > 1.05:\n",
    "            failure.append(t)\n",
    "\n",
    "    # check Hartigan dip test for multimodality\n",
    "    for k in chains[t].keys():\n",
    "        dip, pval = diptest.diptest(chains[t][k].values)\n",
    "        if pval < 0.05:            \n",
    "            failure.append(t)\n",
    "    \n",
    "    try:\n",
    "        use = catalog.planet_name == t\n",
    "        \n",
    "        rho_mu = catalog.loc[use, 'rhostar'].iloc[0]\n",
    "        rho_err1 = np.abs(catalog.loc[use, 'rhostar_err1'].iloc[0])\n",
    "        rho_err2 = np.abs(catalog.loc[use, 'rhostar_err2'].iloc[0])\n",
    "\n",
    "        # don't use highly asymmetric density constraints\n",
    "        if np.abs(rho_err1-rho_err2)/(0.5*(rho_err1+rho_err2)) > 0.30:\n",
    "            failure.append(t)\n",
    "        else:\n",
    "            density[t] = rho_mu, np.sqrt(rho_err1**2 + rho_err2**2)/np.sqrt(2)\n",
    "    \n",
    "    except:\n",
    "        warnings.warn(\"{0} has no recorded density\".format(t))\n",
    "        failure.append(t)\n",
    "\n",
    "targets = list(np.array(targets)[~np.isin(targets,failure)])\n",
    "print(\"{0} targets found with unreliable chains, or posterior samples indicating b > 1 - Rp/Rs\".format(len(np.unique(failure))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b98d63b-692a-42f8-8d3e-f7502c40fefc",
   "metadata": {},
   "source": [
    "## Importance sample $\\{e,\\omega,\\rho_\\star\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ebaa4d-9a82-438d-ac5f-c4614a77a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Importance sampling...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd85a7e-3587-4250-8f01-273639071f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import hyp2f1\n",
    "\n",
    "def jacobian_integral(P, ror, b, T14):\n",
    "    \"\"\"\n",
    "    P   : [days]\n",
    "    T14 : [days]\n",
    "\n",
    "    jac:\n",
    "    \"\"\"\n",
    "    P_   = P*86400.       # [seconds]\n",
    "    dur_ = T14*86400.     # [seconds]\n",
    "    G    = apc.G.value    # Newton's constant\n",
    "\n",
    "    const = (12*pi**3)/(P_**3*G) * (pi*dur_/P_)**-4\n",
    "    dep = (1+ror)**3 * b * hyp2f1(-1.5,0.5,1.5, b**2/(1+ror)**2)\n",
    "\n",
    "    return const*dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88ba1c4-fb21-4dca-b286-0b0ce2d939a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "failure = []\n",
    "\n",
    "for i, t in enumerate(targets):\n",
    "    try:\n",
    "        # true stellar density (tuple) in g/cm3\n",
    "        rho_true = 1.41*density[t][0], 1.41*density[t][1]\n",
    "                   \n",
    "        w, d = imp_sample_rhostar(chains[t], rho_true, ew_obs_prior=False, upsample=500)\n",
    "        d = d.sample(n=NSAMP, replace=True, weights=w, ignore_index=True)\n",
    "\n",
    "        J = jacobian(d.PERIOD, d.ROR, d.IMPACT, d.DUR14)\n",
    "        d = d.sample(n=NSAMP, replace=True, weights=1/np.abs(J), ignore_index=True)\n",
    "        \n",
    "        data[t] = d\n",
    "\n",
    "    except:\n",
    "        warnings.warn(\"{0} failed during sampling and will not be included in the analysis\".format(t))\n",
    "        failure.append(t)\n",
    "\n",
    "targets = list(np.array(targets)[~np.isin(targets,failure)])\n",
    "\n",
    "# update catalog\n",
    "catalog = catalog.loc[np.isin(catalog.planet_name, targets)].reset_index(drop=True)\n",
    "targets = np.array(catalog.planet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fbff79-fe02-490c-81bf-7059e8779969",
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_PLOT = True\n",
    "if DO_PLOT:\n",
    "    sns.set_context('paper', font_scale=1.2)\n",
    "    \n",
    "    if len(targets) > 50:\n",
    "        targets_to_plot = np.random.choice(targets, size=50, replace=False)\n",
    "    else:\n",
    "        targets_to_plot = np.copy(targets)\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "    for i, t in enumerate(targets_to_plot):\n",
    "        e  = data[t].ECC.values\n",
    "        e_ = np.linspace(0,1,1000)\n",
    "    \n",
    "        kde_e = stats.gaussian_kde(np.hstack([-e,e]), bw_method=0.1)\n",
    "        pdf_e_ = 2*kde_e(e_)\n",
    "    \n",
    "        mode_e = e_[np.argmax(pdf_e_)]\n",
    "\n",
    "        my_color = \"lightgrey\"\n",
    "        my_cmap  = LinearSegmentedColormap.from_list(\"my_cmap\", [my_color, \"k\"], N=50)\n",
    "    \n",
    "        plt.plot(e_, pdf_e_, c=my_cmap(mode_e), zorder=100*mode_e, lw=2)\n",
    "        \n",
    "    plt.xlim(0,1)\n",
    "    plt.xlabel(\"$e$\", fontsize=16)\n",
    "    plt.ylabel(\"samples density\", fontsize=16)\n",
    "    plt.ylim(-0.1,5)\n",
    "    plt.yticks([])\n",
    "    \n",
    "    #plt.text(0.98, 4.85, \"Jovians\", fontsize=16, color=my_color, ha='right', va='top')\n",
    "    #plt.savefig(os.path.join(PROJECT_DIR, \"Figures/ecc-posterior-kde-jovians.pdf\"), bbox_inches='tight')\n",
    "    #plt.text(0.98, 4.85, \"$R_p$ = {0:.2f}-{1:.2f}\".format(RAD_LIM[0],RAD_LIM[1]), fontsize=16, color=my_color, ha='right', va='top')\n",
    "    #plt.savefig(os.path.join(PROJECT_DIR, \"Figures/ecc-posterior-kde-{0:.2f}-{1:.2f}.pdf\".format(RAD_LIM[0],RAD_LIM[1])), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b0a4b2-dae5-4ea8-8e13-745a389c8a8d",
   "metadata": {},
   "source": [
    "#### Vectorize quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23af7246-aaab-40cb-939d-915aa499f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_array = {}\n",
    "\n",
    "samples_array['ecc']    = np.zeros((len(targets),NSAMP))\n",
    "samples_array['omega']  = np.zeros((len(targets),NSAMP))\n",
    "samples_array['impact'] = np.zeros((len(targets),NSAMP))\n",
    "samples_array['ln_wt']  = np.zeros((len(targets),NSAMP))\n",
    "\n",
    "for i, t in enumerate(targets):\n",
    "    samples_array['ecc'][i]    = np.array(data[t].ECC)\n",
    "    samples_array['omega'][i]  = np.array(data[t].OMEGA)\n",
    "    samples_array['impact'][i] = np.array(data[t].IMPACT)\n",
    "    samples_array['ln_wt'][i]  = catalog.loc[catalog.planet_name == t, 'ln_binweight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2ea926-34d2-4b4d-9c13-684deb2b5356",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(targets)\n",
    "ecc = np.median(samples_array['ecc'], axis=1)\n",
    "use = ecc > np.percentile(ecc, 100*(N-8)/N)\n",
    "high_e_catalog = catalog.loc[np.isin(catalog.planet_name, targets[use])]\n",
    "\n",
    "high_e_catalog['planet_name period rp'.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86854a25-ab52-49b0-9363-b7fa69f86093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, t in enumerate(high_e_catalog.planet_name):\n",
    "for i, t in enumerate(targets):\n",
    "    print(t)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(12,3))\n",
    "\n",
    "    b_ = np.linspace(0,1,21)\n",
    "    r_ = np.median(chains[t].ROR)\n",
    "    T_ = np.median(chains[t].DUR14)\n",
    "    P_ = np.median(chains[t].PERIOD)\n",
    "\n",
    "    J_ = np.abs(jacobian(P_, r_, b_, T_))\n",
    "    J_ = J_ / np.sum(J_) * 20\n",
    "    \n",
    "    ax[0].hist(chains[t].IMPACT, bins=np.linspace(0,1,21), color='lightgrey', density=True)\n",
    "    ax[0].hist(chains[t].IMPACT, bins=np.linspace(0,1,21), color='k', histtype='step', density=True)\n",
    "    ax[0].plot(b_, J_, color='r', lw=2)\n",
    "    ax[0].set_title('Raw chains', fontsize=16)\n",
    "    ax[0].set_yticks([])\n",
    "    \n",
    "    ax[1].hist(data[t].IMPACT, bins=np.linspace(0,1,21), color='lightgrey')\n",
    "    ax[1].hist(data[t].IMPACT, bins=np.linspace(0,1,21), color='k', histtype='step')\n",
    "    ax[1].set_title('Importance weighting', fontsize=16)\n",
    "    ax[1].set_yticks([])\n",
    "\n",
    "    w = stats.beta(a=0.52, b=3.76).pdf(data[t].ECC) * (1-data[t].ECC**2)\n",
    "    w /= np.sum(w)\n",
    "\n",
    "    ax[2].hist(data[t].IMPACT, weights=w, bins=np.linspace(0,1,21), color='lightgrey')\n",
    "    ax[2].hist(data[t].IMPACT, weights=w, bins=np.linspace(0,1,21), color='k', histtype='step')\n",
    "    ax[2].set_title('With shrinkage', fontsize=16)\n",
    "    ax[2].set_yticks([])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabc1294-8e9a-487f-9957-21b75d0b4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, t in enumerate(high_e_catalog.planet_name):\n",
    "for i, t in enumerate(targets):\n",
    "    print(t)\n",
    "\n",
    "    w = stats.beta(a=0.52, b=3.76).pdf(data[t].ECC) * (1-data[t].ECC**2)\n",
    "    w /= np.sum(w)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(12,3))\n",
    "    \n",
    "    ax[0].hist(data[t].ECC, weights=None, bins=np.linspace(0,1,21), color='indigo', lw=2, histtype='step', density=True, label=\"raw data\")\n",
    "    ax[0].hist(data[t].ECC, weights=w, bins=np.linspace(0,1,21), color='mediumseagreen', lw=2, histtype='step', density=True, label=\"with shrinkage\")\n",
    "    ax[0].set_title('ECC', fontsize=20)\n",
    "    ax[0].set_yticks([])\n",
    "    ax[0].legend()\n",
    "    \n",
    "    ax[1].hist(data[t].OMEGA, weights=None, bins=21, color='indigo', lw=2, histtype='step', density=True)\n",
    "    ax[1].hist(data[t].OMEGA, weights=w, bins=21, color='mediumseagreen', lw=2, histtype='step', density=True)\n",
    "    ax[1].set_title('OMEGA', fontsize=20)\n",
    "    ax[1].set_yticks([])\n",
    "\n",
    "    ax[2].hist2d(data[t].ECC, data[t].OMEGA, weights=w, bins=(np.linspace(0,1,21), np.linspace(-0.5*pi,1.5*pi,21)))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f3ea4a-47c4-4a84-bcce-66e909c2d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in enumerate(targets):\n",
    "    print(t)\n",
    "\n",
    "    w = stats.beta(a=0.52, b=3.76).pdf(data[t].ECC) * (1-data[t].ECC**2)\n",
    "    w /= np.sum(w)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3,3))\n",
    "\n",
    "    bins = (np.linspace(0,1,51), np.linspace(data[t].DUR14.min(), data[t].DUR14.max(),51)*24)\n",
    "\n",
    "    ax.hist2d(data[t].IMPACT, data[t].DUR14*24, weights=None, bins=bins)\n",
    "    ax.set_xlabel(\"$b$\")\n",
    "    ax.set_ylabel(\"$T_{14}$ (hrs)\")\n",
    "\n",
    "    plt.savefig(os.path.join(PROJECT_DIR, \"Figures/samples_histograms/{0}-b-T14.pdf\".format(t)), bbox_inches='tight')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f89d86-2748-4199-b044-deebdf95795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, t in enumerate(high_e_catalog.planet_name):\n",
    "for i, t in enumerate(targets):\n",
    "    print(t)\n",
    "\n",
    "    w = stats.beta(a=0.52, b=3.76).pdf(data[t].ECC) * (1-data[t].ECC**2)\n",
    "    w /= np.sum(w)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(6,3))\n",
    "    \n",
    "    ax[0].hist2d(data[t].IMPACT, data[t].ECC, bins=(np.linspace(0,1,51), np.linspace(0,1,51)))\n",
    "    ax[0].set_xlabel(\"$b$\")\n",
    "    ax[0].set_ylabel(\"$e$\")\n",
    "\n",
    "    ax[1].hist2d(data[t].OMEGA, data[t].ECC, bins=(np.linspace(-0.5*pi,1.5*pi,51), np.linspace(0,1,51)))\n",
    "    ax[1].set_xlabel(\"$\\omega$\")\n",
    "    ax[1].set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(os.path.join(PROJECT_DIR, \"Figures/samples_histograms/{0}-e-b-omega-raw.pdf\".format(t)), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e3cfb-5305-4750-9d97-10fea57ddce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, t in enumerate(high_e_catalog.planet_name):\n",
    "for i, t in enumerate(targets):\n",
    "    print(t)\n",
    "\n",
    "    w = stats.beta(a=0.52, b=3.76).pdf(data[t].ECC) * (1-data[t].ECC**2)\n",
    "    w /= np.sum(w)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(6,3))\n",
    "    \n",
    "    ax[0].hist2d(data[t].IMPACT, data[t].ECC, weights=w, bins=(np.linspace(0,1,51), np.linspace(0,1,51)))\n",
    "    ax[0].set_xlabel(\"$b$\")\n",
    "    ax[0].set_ylabel(\"$e$\")\n",
    "\n",
    "    ax[1].hist2d(data[t].OMEGA, data[t].ECC, weights=w, bins=(np.linspace(-0.5*pi,1.5*pi,51), np.linspace(0,1,51)))\n",
    "    ax[1].set_xlabel(\"$\\omega$\")\n",
    "    ax[1].set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PROJECT_DIR, \"Figures/samples_histograms/{0}-e-b-omega-shrunk.pdf\".format(t)), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8cdfdc-5840-446f-b2d9-a0c11007317b",
   "metadata": {},
   "source": [
    "## Run hierarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f336b-ebb4-49c6-80a9-5d9a5f5306dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running hierarchical MCMC using {0} planets\".format(len(samples_array['ecc'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b50187-44bb-4058-a96f-70aa6cff735a",
   "metadata": {},
   "source": [
    "#### Load empirical distribution template (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ad89e-b260-4f91-9d3b-b99c85b98bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DISTRIBUTION == 'empirical':\n",
    "    template_values = np.loadtxt(os.path.join(PROJECT_DIR, \"template_distribution.txt\")).T\n",
    "    template_spline = CubicSpline(template_values[0], template_values[1], extrapolate=False)\n",
    "else:\n",
    "    template_values = None\n",
    "    template_spline = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87743ebd-c7c1-4d67-af1b-52de5cc70460",
   "metadata": {},
   "source": [
    "#### Build model and run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21acb44c-93d5-43df-8b76-cde96ba1faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model and sample from posterior\n",
    "model, bin_edges = build_simple_model(samples_array,\n",
    "                                      DISTRIBUTION,\n",
    "                                      NBIN,\n",
    "                                      e_detprior=E_DETPRIOR,\n",
    "                                      b_detprior=B_DETPRIOR,\n",
    "                                      template_spline=template_spline,\n",
    "                                      eps=1e-6)\n",
    "\n",
    "with model:\n",
    "    trace = pmx.sample(tune=3000, draws=1000, chains=2, target_accept=0.95, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d5ded-f271-4bac-b041-8659562e524b",
   "metadata": {},
   "source": [
    "## Leave N Out validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27360cc-4522-48e8-8fb1-53184b311fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "npl = samples_array['ecc'].shape[0]\n",
    "rank = np.array(stats.rankdata(np.median(samples_array['ecc'], axis=1)), dtype='int')\n",
    "traces = []\n",
    "\n",
    "for n in range(21):\n",
    "    # remove N planets with the highest eccentricity\n",
    "    use = rank <= npl - n\n",
    "    \n",
    "    samples_copy = {}\n",
    "    for k in samples_array.keys():\n",
    "        samples_copy[k] = samples_array[k][use]\n",
    "\n",
    "    print(\"Running hierarchical MCMC using {0} planets\".format(len(samples_copy['ecc'])))\n",
    "\n",
    "    \n",
    "    # build model and sample from posterior\n",
    "    model, bin_edges = build_simple_model(samples_copy,\n",
    "                                          DISTRIBUTION,\n",
    "                                          NBIN,\n",
    "                                          e_detprior=E_DETPRIOR,\n",
    "                                          b_detprior=B_DETPRIOR,\n",
    "                                          template_spline=template_spline,\n",
    "                                          eps=1e-6)\n",
    "    \n",
    "    with model:\n",
    "        trace = pmx.sample(tune=3000, draws=1000, chains=2, target_accept=0.95, return_inferencedata=True)\n",
    "\n",
    "    # track results\n",
    "    traces.append(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0ddd6a-e9d3-43bc-84b7-f65b1a1b50b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ecc = np.zeros((len(traces),3))\n",
    "\n",
    "for i, trace in enumerate(traces):\n",
    "    mean_ecc[i] = np.percentile(trace.posterior.mean_ecc.values, [16,50,84], axis=(0,1))\n",
    "\n",
    "x = np.arange(len(traces))\n",
    "y = mean_ecc[:,1]\n",
    "yerr = np.abs(mean_ecc[:,(0,2)].T - mean_ecc[:,1])\n",
    "\n",
    "sns.set_context('paper', font_scale=1.2)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "#plt.errorbar(x, y, yerr=yerr, fmt='ko')\n",
    "plt.errorbar(x, y, yerr=yerr, fmt='o', color=my_color)\n",
    "plt.xlim(-0.5,20.5)\n",
    "plt.xticks([0,4,8,12,16,20])\n",
    "plt.ylim(0,0.4)\n",
    "plt.xlabel(\"number of planets removed\", fontsize=16)\n",
    "plt.ylabel(\"mean eccentricity\", fontsize=16)\n",
    "#plt.text(20, 0.39, \"Jovians\", fontsize=16, color=my_color, ha='right', va='top')\n",
    "#plt.savefig(os.path.join(PROJECT_DIR, \"Figures/leave-n-out-validation-jovians.pdf\"), bbox_inches='tight')\n",
    "#plt.text(20, 0.29, \"$R_p$ = {0:.2f}-{1:.2f}\".format(RAD_LIM[0],RAD_LIM[1]), fontsize=16, ha='right', va='top')\n",
    "#plt.savefig(os.path.join(PROJECT_DIR, \"Figures/leave-n-out-validation-{0:.2f}-{1:.2f}.pdf\".format(RAD_LIM[0],RAD_LIM[1])), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f83d1d-1b03-47af-b94a-62308406220b",
   "metadata": {},
   "source": [
    "## Save posterior trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a53ea6f-fea7-4ed4-aaa8-0dcf3257e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refactor dataframe for export\n",
    "df = trace.to_dataframe(groups='posterior', include_coords=False)\n",
    "\n",
    "column_map = {}\n",
    "for k in list(df.keys()):    \n",
    "    if k.find('[') == -1:\n",
    "        column_map[k] = k\n",
    "    else:\n",
    "        column_map[k] = k[:k.find('[')] + '_{:02d}'.format(int(k[k.find('[')+1:-1]))\n",
    "\n",
    "df = df.rename(columns=column_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c125c92b-c24d-4a94-abfd-6e7f816dfc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "\n",
    "primary_hdu = fits.PrimaryHDU()\n",
    "header = primary_hdu.header\n",
    "\n",
    "header['YYYYMMDD'] = YYYYMMDD\n",
    "header['DIST']     = DISTRIBUTION\n",
    "header['NSAMP']    = NSAMP\n",
    "header['NBIN']     = NBIN\n",
    "header['NOBJ']     = samples_array['ecc'].shape[0]\n",
    "header['MULT_0']   = MULTIPLICITY[0]\n",
    "header['MULT_1']   = MULTIPLICITY[1]\n",
    "header['PER_0']    = PER_LIM[0]\n",
    "header['PER_1']    = PER_LIM[1]\n",
    "header['RAD_TYPE'] = RAD_TYPE\n",
    "header['RAD_0']    = RAD_LIM[0]\n",
    "header['RAD_1']    = RAD_LIM[1]\n",
    "header['RAD_FWHM'] = RAD_FWHM\n",
    "header['MSTAR_0']  = MSTAR_LIM[0]\n",
    "header['MSTAR_1']  = MSTAR_LIM[1]\n",
    "header['RSTAR_0']  = RSTAR_LIM[0]\n",
    "header['RSTAR_1']  = RSTAR_LIM[1]\n",
    "header['FEH_0']    = FEH_LIM[0]\n",
    "header['FEH_1']    = FEH_LIM[1]\n",
    "header['TEFF_0']   = TEFF_LIM[0]\n",
    "header['TEFF_1']   = TEFF_LIM[1]\n",
    "header['AGE_0']    = AGE_LIM[0]\n",
    "header['AGE_1']    = AGE_LIM[1]\n",
    "header['E_PRIOR']  = E_DETPRIOR\n",
    "header['B_PRIOR']  = B_DETPRIOR\n",
    "\n",
    "samples_hdu = fits.BinTableHDU(data=df.to_records(index=False), name='SAMPLES')\n",
    "binedges_hdu = fits.ImageHDU(bin_edges, name='BINEDGES')\n",
    "\n",
    "hduL  = fits.HDUList([primary_hdu, samples_hdu, binedges_hdu])\n",
    "fname = os.path.join(RESULTS_DIR, \"{0}_{1}.fits\".format(YYYYMMDD, RUN_ID))\n",
    "\n",
    "hduL.writeto(fname, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794cd6f9-657d-4b6e-bc79-388befce9693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this complicated loading routine deals with big-endian vs little-endian mismatch between pandas and FITS\n",
    "with fits.open(fname) as hduL:\n",
    "    data = hduL['SAMPLES'].data\n",
    "    keys = data.names\n",
    "    \n",
    "    _samples = []\n",
    "    for k in keys:\n",
    "        _samples.append(data[k])\n",
    "\n",
    "    samples = pd.DataFrame(np.array(_samples).T, columns=keys)\n",
    "    bin_edges = np.array(hduL['BINEDGES'].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637829d9",
   "metadata": {},
   "source": [
    "## Inspect VanEylen+19 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b09d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load VanEylen+19 catalog\n",
    "VE19 = os.path.join(PROJECT_DIR, 'Catalogs/vaneylen_2019_asteroseismology_singles.txt')\n",
    "ve19 = pd.read_csv(VE19, skiprows=4, skipfooter=1, delimiter='\\t', usecols=[1,2,3], engine='python')\n",
    "ve19 = ve19.rename(columns={'Unnamed: 1': 'koi_id', 'e (mode)': 'e_mode_ve', 'e (68%)': 'e_hdi_ve'})\n",
    "\n",
    "koi_id_ve = []\n",
    "e_mode_ve = []\n",
    "e_hdi_ve_1 = []\n",
    "e_hdi_ve_2 = []\n",
    "\n",
    "for i, t in enumerate(ve19.koi_id):\n",
    "    raw = ve19.e_hdi_ve[i][1:-1].split()\n",
    "    \n",
    "    koi_id_ve.append('K'+str(t[4:]).zfill(8))\n",
    "    e_mode_ve.append(ve19.e_mode_ve[i])\n",
    "    e_hdi_ve_1.append(float(raw[0].replace(',', '')))\n",
    "    e_hdi_ve_2.append(float(raw[1].replace(',', '')))\n",
    "\n",
    "\n",
    "ve19 = pd.DataFrame()\n",
    "ve19['koi_id'] = koi_id_ve\n",
    "ve19['e_mode_ve'] = e_mode_ve\n",
    "ve19['e_hdi_ve_1'] = e_hdi_ve_1\n",
    "ve19['e_hdi_ve_2'] = e_hdi_ve_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa82a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load DR25 catalog\n",
    "DR25_CATALOG = os.path.join(PROJECT_DIR, 'Catalogs/kepler_dr25_gaia_dr2_crossmatch.csv')\n",
    "catalog = pd.read_csv(DR25_CATALOG, index_col=0)\n",
    "\n",
    "keep = np.isin(catalog.planet_name, koi_id_ve)\n",
    "\n",
    "catalog = catalog.loc[keep].reset_index(drop=True)\n",
    "targets = np.array(catalog.planet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6041f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "koi_id_gp = []\n",
    "e_mode_gp = []\n",
    "e_hdi_gp_1 = []\n",
    "e_hdi_gp_2 = []\n",
    "\n",
    "for i, t in enumerate(targets):\n",
    "    raw = az.hdi(data[t].ECC.values, hdi_prob=0.68)\n",
    "\n",
    "    koi_id_gp.append(t)\n",
    "    e_mode_gp.append(az.plots.plot_utils.calculate_point_estimate('mode', data[t].ECC.values).round(2))\n",
    "    e_hdi_gp_1.append(raw[0].round(2))\n",
    "    e_hdi_gp_2.append(raw[1].round(2))\n",
    "\n",
    "gp24 = pd.DataFrame()\n",
    "gp24['koi_id'] = koi_id_gp\n",
    "gp24['e_mode_gp'] = e_mode_gp\n",
    "gp24['e_hdi_gp_1'] = e_hdi_gp_1\n",
    "gp24['e_hdi_gp_2'] = e_hdi_gp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f7bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([ve19.set_index('koi_id'), gp24.set_index('koi_id')], axis=1, join='inner').reset_index()\n",
    "df.to_csv(os.path.join(PROJECT_DIR, \"ve19_gp24_singles_compare.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ca9a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('e_mode_gp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5850b607",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.e_mode_ve.values\n",
    "y = df.e_mode_gp.values\n",
    "\n",
    "xerr = np.abs((df.e_hdi_ve_1 - x, df.e_hdi_ve_2-x))\n",
    "yerr = np.abs((df.e_hdi_gp_1 - y, df.e_hdi_gp_2-y))\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(x, y, xerr=xerr, yerr=yerr, fmt='ko', alpha=0.3, capsize=3)\n",
    "plt.plot(np.linspace(0,1), np.linspace(0,1), 'r:')\n",
    "plt.xlabel(\"VE+19\", fontsize=16)\n",
    "plt.ylabel(\"GP24\", fontsize=16)\n",
    "plt.title(\"SINGLES\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53512145",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,2))\n",
    "plt.plot(x, y-x, 'ko', alpha=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
